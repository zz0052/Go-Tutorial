### For-learning-Go-Tutorial

Go语言是谷歌2009发布的第二款开源编程语言

Go语言专门针对多处理器系统应用程序的编程进行了优化，使用Go编译的程序可以媲美C或C++代码的速度，而且更加安全、支持并行进程。

因而一直想的是自己可以根据自己学习和使用Go语言编程的心得，写一本Go的书可以帮助想要学习Go语言的初学者快速入门开发和使用！


#### TiDB的使用
在使用TiDB的时候首先要搭建集群，看了下官网有三种部署方法。（Ansible 部署方案），Docker部署方案，Binary部署方案。目前我这里是用了 Docker部署方案和Binary部署方案安装部署的TiDB集群．一个完整的 TiDB 集群包括 PD，TiKV 以及 TiDB。启动顺序依次是 PD，TiKV 以及 TiDB。

这里有三点需要注意的:

* 快速了解和试用 TiDB，推荐使用单节点方式快速部署。

* 功能性测试 TiDB，推荐使用功能性测试部署。

* 生产环境使用 TiDB，推荐使用多节点集群模式部署。

#### Docker部署方案

首先安装docker环境，这个可以根据电脑系统的不同，选择不同的安装方式。
* [Mac安装](https://docs.docker.com/docker-for-mac/install/)
* [Unbantu安装](https://docs.docker.com/install/linux/docker-ce/ubuntu/)
* [Windows安装](https://docs.docker.com/docker-for-windows/install/)
* [centos安装](https://docs.docker.com/install/linux/docker-ce/centos/)

不过我这里是用脚本直接在centos上直接安装的:
```bash
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo;

yum-config-manager --enable docker-ce-edge;

yum-config-manager --disable docker-ce-edge;

yum install docker-ce;

systemctl start docker.service;
systemctl enable docker.service;
```

##### 拉取TiDB的Docker镜像

这里需要拉取TiDB的三个镜像,TiDB,TiDB,PD,因为TiDB集群部署主要包括这三个服务组件.

* TiDB Server

iDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。

* PD Server
Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个： 一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。

PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。

* TiKV Server

TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range （从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region 。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。

然后拉取Docker最新镜像可以通过[Docker官方镜像仓库](https://hub.docker.com/)获取：

```bash
docker pull pingcap/tidb:latest
docker pull pingcap/tikv:latest
docker pull pingcap/pd:latest
```

| 主机名      | IP            | 部署服务            | 数据盘挂载            |
| ---- | ------------------------------- |----------------- |----------------- |
|host1| 120.92.150.39|PD1 & TiDB|/data|
|host2| 120.92.163.32|PD2|/data|
|host3| 120.92.172.35 |TiKV1|/data|
|host4| 120.92.169.191|TiKV2|/data|
|host5| 120.92.165.229|TiKV3|/data|

然后需要在host1上配置下免密登录:
```bash
> ssh-keygen -t rsa

>  ls -la .ssh
总用量 16
drwx------  2 usera usera 4096  7月 23 09:22 .
drwxrwx--- 12 usera usera 4096  7月 23 09:22 ..
-rw-------  1 usera usera 1675  7月 23 09:22 id_rsa
-rw-r--r--  1 usera usera  399  7月 23 09:22 id_rsa.pub
```

此时会在/.ssh目录下生成密钥对,然后将公钥上传到其他主机上 服务器的，并以userb用户登录.

```bash
> ssh-copy-id .ssh/id_rsa.pub root@120.92.163.32

> ssh-copy-id .ssh/id_rsa.pub root@120.92.172.35

> ssh-copy-id .ssh/id_rsa.pub root@120.92.169.191

> ssh-copy-id .ssh/id_rsa.pub root@120.92.165.229
```

这样我们就可以使用免密登录了:

```bash
> ssh root@120.92.163.32

> ssh root@120.92.172.35

> ssh root@120.92.169.191

> ssh root@120.92.165.229
```
除此之外也可以用scp命令实现，但是有点麻烦:
```bash
> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.163.32:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.172.35:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.169.191:~/

> scp -P 22 ~/.ssh/id_rsa.pub root@120.92.165.229:~/

```
##### 启动PD
登录 host1 执行：
```bash
> docker run -d --name pd1 \
  -p 2379:2379 \
  -p 2380:2380 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/pd:latest \
  --name="pd1" \
  --data-dir="/data/pd1" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://120.92.150.39:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://120.92.150.39:2380" \
  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http:// 120.92.163.32:2380"
```

登录 host2 执行：
```bash
> docker run -d --name pd2 \
  -p 2379:2379 \
  -p 2380:2380 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/pd:latest \
  --name="pd2" \
  --data-dir="/data/pd2" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://120.92.163.32:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://120.92.163.32:2380" \
  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"
```

##### 启动 TiKV

登录 host3 执行：
```bash
docker run -d --name tikv1 \
 -p 20160:20160 \
 --ulimit nofile=1000000:1000000 \
 -v /etc/localtime:/etc/localtime:ro \
 -v /data:/data \
 pingcap/tikv:latest \
 --addr="0.0.0.0:20160" \
 --advertise-addr=" 120.92.172.35:20160" \
 --data-dir="/data/tikv1" \
 --pd="120.92.150.39:2379, 120.92.163.32:2379"
```


登录 host4 执行：
```bash
docker run -d --name tikv2 \
  -p 20160:20160 \
  --ulimit nofile=1000000:1000000 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/tikv:latest \
  --addr="0.0.0.0:20160" \
  --advertise-addr="120.92.169.191:20160" \
  --data-dir="/data/tikv2" \
  --pd="120.92.150.39:2379, 120.92.163.32:2379"
```
登录 host5 执行：
```bash
docker run -d --name tikv3\
  -p 20160:20160 \
  --ulimit nofile=1000000:1000000 \
  -v /etc/localtime:/etc/localtime:ro \
  -v /data:/data \
  pingcap/tikv:latest \
  --addr="0.0.0.0:20160" \
  --advertise-addr=" 120.92.165.229 :20160" \
  --data-dir="/data/tikv2" \
  --pd="120.92.150.39 :2379, 120.92.163.32:2379"
```

##### 启动 TiDB

登录 host1 执行：
```bash
docker run -d --name tidb \
  -p 4000:4000 \
  -p 10080:10080 \
  -v /etc/localtime:/etc/localtime:ro \
  pingcap/tidb:latest \
  --store=tikv \
  --path="120.92.172.35:2379,120.92.169.191:2379,120.92.165.229:2379"
```
登录 host1并确保已安装 MySQL 命令行客户端，执行：
```bash
$ mysql -h 127.0.0.1 -P 4000 -u root -D test
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| INFORMATION_SCHEMA |
| PERFORMANCE_SCHEMA |
| mysql              |
| test               |
+--------------------+
4 rows in set (0.00 sec)
```
#### Binary部署方案

除了上面Docker安装部署，我们也可以用Binary安装和部署TiDB集群．

用Binary部署TiDB需要下载对应的压缩包:

* [tidb-latest-linux-amd64](http://download.pingcap.org/tidb-latest-linux-amd64.tar.gz).

* [tidb-latest-linux-amd64.sha256](http://download.pingcap.org/tidb-latest-linux-amd64.sha256)．

在centos上可以用:
```bash
> wget http://download.pingcap.org/tidb-latest-linux-amd64.targz 

> wget http://download.pingcap.org/tidb-latest-linux-amd64.sha256
```
然后检查文件完整性，返回 ok 则正确．
```bash
> sha256sum -c tidb-latest-linux-amd64.sha256
```
解开压缩包:
```bash
> tar -xzf tidb-latest-linux-amd64.tar.gz cd tidb-latest-linux-amd64
```
我们可以在单机上面，运行和测试 TiDB 集群，请按如下步骤依次启动 PD，TiKV，TiDB.
```bash
#启动 PD
> ./bin/pd-server --data-dir=/data/tidb/pd \
                --log-file=pd.log
#启动 TiKV
> ./bin/tikv-server --pd="127.0.0.1:2379" \
                  --data-dir=/data/tidb/pd \
                  --log-file=tikv.log
#启动 TiDB
> ./bin/tidb-server --store=tikv \
                  --path="127.0.0.1:2379" \
                  --log-file=tidb.log
#使用官方的 mysql 客户端连接 TiDB
> mysql -h 127.0.0.1 -P 4000 -u root -D test

#多节点集群模式部署
```

这里我用了和上面Docker部署一样的５台服务器，２个PD,1个TiDB,和３个TiKV来部署TiDB集群.

| 主机名      | IP            | 部署服务            | 数据盘挂载            |
| ---- | ------------------------------- |----------------- |----------------- |
|host1| 120.92.150.39|PD1 & TiDB|/data|
|host2| 120.92.163.32|PD2|/data|
|host3| 120.92.172.35 |TiKV1|/data|
|host4| 120.92.169.191|TiKV2|/data|
|host5| 120.92.165.229|TiKV3|/data|

```bash
# 在 host1，host2上依次启动 PD:
> ./bin/pd-server --name=pd1 \
                  --data-dir=/data/tidb/pd1 \
                  --client-urls="http://120.92.150.39:2379" \
                  --peer-urls="http://120.92.150.39:2380" \
                  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"　\
                  --log-file=pd1.log

> ./bin/pd-server --name=pd2 \
                  --data-dir=/data/tidb/pd2 \
                  --client-urls="http://120.92.163.32:2379" \
                  --peer-urls="http://120.92.163.32:2380" \
                  --initial-cluster="pd1=http://120.92.150.39:2380,pd2=http://120.92.163.32:2380"　\
                  --log-file=pd2.log

# 在 host3，host4，host5上启动 TiKV
> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.172.35:20160" \
                    --data-dir=/data/tidb/tikv1 \
                    --log-file=tikv1.log
                  

> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.169.191:20160" \
                    --data-dir=/data/tidb/tikv2 \
                    --log-file=tikv2.log
                    
> ./bin/tikv-server --pd="120.92.150.39:2379,120.92.163.32:2379" \
                    --addr="120.92.165.229:20160" \
                    --data-dir=/data/tidb/tikv3 \
                    --log-file=tikv3.log

# 在 host1上启动 TiDB

> ./bin/tidb-server --store=tikv \
                    --path="120.92.172.35:2379,120.92.169.191:2379,120.92.165.229:2379" \               
                    --log-file=tidb.log
                    
# 使用官方 mysql 客户端连接 TiDB
> mysql -h 120.92.150.39 -P 4000 -u root -D test
```
注意：在生产环境中启动 TiKV时，建议使用--config参数指定配置文件路径。

如果使用 nohup 在生产环境中启动集群，需要将启动命令放到一个脚本文件里面执行，否则会出现因为 Shell 退出导致 nohup 启动的进程也收到异常信号退出的问题，具体参考进程异常退出。 功能性测试部署．
